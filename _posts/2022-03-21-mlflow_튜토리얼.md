---
layout: post
title:  "[컨텐츠 연재] #01 간단하게 살펴보는 MLflow"
author: 김소연
categories: [ 컨텐츠 ]
image: assets/images/pseudo-contents/contents_mlflow.jpg
---


안녕하세요, 가짜연구소입니다.

가짜연구소는 **machine learning 연구를 중심으로 모인 비영리 커뮤니티**입니다. 
어느덧 3기가 마무리되고 4기 모집까지 성공적으로 마무리되었는데요! 
가짜연구소 안에서는 현재까지 총 다양한 스터디와 크루가 만들어나간 프로젝트와 더불어 자유로운 질의응답이 이루어지고 있는만큼 엄청난 양의 지식이 공유되었겠죠~?
가짜연구소에서 지향하는 **공유, 동기부여, 함께하는 즐거움**의 가치 실현을 위해 그동안 내부적으로 축적된 AI 관련된 지식을 컨텐츠형으로 공유하고, 확장하고자 해요.
기초 딥러닝, 컴퓨터 비전, 자연어처리 외에도 MLOps, GNN, XAI 그리고 캐글 대회와 관련된 내용을 컨텐츠로 연재할 예정이니 *많은 관심!* **뜨거운 관심!** `꾸준한 관심!` 부탁드리겠습니다.
그럼, 이제 이번 컨텐츠로 *흘러들어*가볼 까요~~?

<br/>

![intro](https://user-images.githubusercontent.com/40655873/159262760-21ce9bbf-7186-4735-8176-0f47545b5b39.png)

### Contents
* [왜 필요하고, 중요하죠?](#왜-필요하고-중요하죠)
* [MLflow 탄생 배경: MLOps](#MLOps가-무엇인가요)
* [MLflow 소개](#MLflow-소개합니다)
  
* [MLflow 주요 컨셉](#MLflow-주요-컨셉은-뭘까요)
* [가짜 연구소에서 진행된 간단한 MLflow 튜토리얼](#에멜플로우로-흘러들어가보시죠)
* [튜토리얼 시작 배경과 후기(추천!)](#MLflow-Tutorial-배경과-후기-with-이정훈-빌더)
* [글을 마무리하며](#글을-마무리하며)

<br/>
<br/>

---

<br/>

# 왜 필요하고 중요하죠
이 글을 읽는 여러분은 크고 작은 머신러닝, 딥러닝 실험을 돌릴 때 어떻게 정리하시나요? 
*혹시..* learning rate를 다르게 설정하고 실험했지만...무심코 돌린 실험 로그들 때문에 뭐가 뭔지 헷갈려서 다시 돌리고..
이번에는 다른 하이퍼파라미터 때문에 다시 돌렸다가..모델 이름이 헷갈려 다시 처음부터 실험해본 적 수없으신가요?  
그런적이 없다구요? 그럼 *혹시..* 여러가지 실험 셋팅에서 최적의 결과를 얻기 위해 엑셀로 정리하다 너무 결과값이 좋거나 이상해서 다시 봤더니 입력이 잘못
들어간거란 걸 알고 슬프거나 가슴을 쓸어내린 적이 없으신가요?  
아.. 없으시다구요? 그럼 *혹시..* 너무 예쁘게 나온 실험 결과를 협업분들에게 공유하려니 다른 PC라서 
설치 패키지나 명령어 다 알려줬는데 알수 없는 오류와 임박한 시간 때문에 캡쳐로 찍어준 경험은 없나요!?  
아하.. 없으시다구요? 그럼 이미 고수시네요..! 그럼 마지막으로 **혹시..** 너무 사랑스러운 본인의 프로젝트를 서비스화하기 위해 배포하려고보니.. 
알아야하는 것도 너무 많고 배포 관리에 필요한 모델이 너무 많아서 잠을 줄여가며 고생한 적은 없나요..?
(다 없으시다면 **뒤로가기** 권장..)

한번쯤은 겪었을 위 고민들을 해결하기 위해 다양한 툴이 나와있는데요. 가짜연구소 컨텐츠의 포문을 열어줄 첫번째 토픽은 
바로 머신러닝 라이프사이클을 관리할 수 있는 mlflow에 대한 내용입니다!
간단한 mlflow소개로 시작, 현재 가짜연구소 아카데믹 및 커뮤니티 빌더를 맡고 있는 이정훈님이 총 3회에 걸쳐 진행한 
mlflow 튜토리얼에서 다룬 내용 일부를 직접 설치해보고 실험해보는 것까지를 다룰거에요!! 마지막으로 정훈님이 현업에서 느낀 MLOps, mlflow
필요성에 대한 인터뷰도 있으니 끝까지 재밌게 읽어주세요 :)


# MLOps가 무엇인가요
간략하게 설명 드려볼게요! 
시스템의 기능을 개발하는 과정에서 그 생산성을 높일 수 있는 것을 크게 아울러 DevOps라고 하는데요. 
MLOps는 머신러닝이 적용된 기능을 서비스에 적용하기 위해 필요한 데이터 관리, 모델 학습 및 추론과 배포에서
생산성을 높일 수 있는 것들을 아우르는 것이라고 볼 수 있어요.


# MLflow 소개합니다

최적의 모델을 결정하기 위해서는 여러 실험이 수반되겠죠? 이 과정에서 실험 셋팅을 다양하게 바꿔가며 여러 메트릭을 토대로 
동료분들과 의사결정을 나누게 될텐데요. 실험이 많아질수록 효과적인 실험 관리 및 공유의 편리성은 더욱 중요해지죠.
이러한 수요 아래에 이미 여러 유료 및 무료버전의 여러 실험 관리 툴이 만들어졌는데요. 대표적으로 weight & bias 가 떠오르실거에요.
하지만 weight & bias 경우 무료 개인 계정으로는 사용 가능한 팀 프로젝트가 1개로 제한되어 있고, 회사에서 사용하려면 이용료를 지불해야해요.
mlflow는 간편한 실험 관리 및 간단한 배포 기능을 제공해주는 end-to-end machine learning lifecycle
관리해주는, 오픈소스 플랫폼이에요.

# MLflow 주요 컨셉은 뭘까요

![concept](https://user-images.githubusercontent.com/40655873/159262721-38836997-1865-449e-99f8-aa1bd2133470.png)

* mlflow tracking : 파라미터와 결과를 비교하기 위해 실험 결과 저장
* mlflow projects: 머신러닝 코드를 재사용하고 재현 가능한 형태로 포장. 포장된 형태를 다른 협업자에게 공유 및 프로덕션에 반영
* mlflow model registry : mlflow model에 사용되는 전체적 라이프 사이클에 관여하는 모델 저장소, API 및 UI 기능 관리
* mlflow models: 다양한 ML 라이브러리에서 모델을 관리하고 배포, serving, 추론

더 자세한 사항은 [mlflow](https://www.mlflow.org/docs/latest/concepts.html) 공식 사이트에서 확인해주세요 :)

<br/>

---
<br/>

# 에멜플로우로 흘러들어가보시죠

본 섹션에서는에서는 mlflow tracking을 통해서 실험 관리, ml registry에 저장된 모델을 간단하게 서빙해보는 것을 알려드릴게요.
내용은 가짜연구소에서 간단하게 진행한 [튜토리얼 내용](https://github.com/vhrehfdl/mlflow_tutorial)을 주로 다루고 있어요. 

### 환경 셋업
1. 튜토리얼에서 진행한 [github](https://github.com/vhrehfdl/mlflow_tutorial) 에서 코드를 클론해주세요.
```
git clone https://github.com/vhrehfdl/mlflow_tutorial
```

2. 실험에 필요한 라이브러리를 설치해주세요.
    * mlflow만 설치할거라면 `pip install mlflow` 를 해주셔도 좋지만, 본 튜토리얼에서 torchtext 등의 라이브러리도 사용하요.
    * 위의 `pip` 로 mlflow 설치가 안되고 conda 환경을 사용하신다면 `conda install mlflow`로도 시도해보세요.
  
```
pip install -r requirements.txt
```
3. 현재 실험에서 사용한 mlflow 버전은 다음과 같아요.
   
```
mlflow, version 1.24.0
```

> Notice: 
> 본 실험을 수행한 에디터는 m1 맥 노트북을 사용했습니다.
> 이후 명령어에서 `--no-conda가` 있다면 conda 환경을 사용하지 않는 것이고 없다면 사용하는 것입니다.
```
mlflow, version 1.24.0
```

### 기본적인 모델 훈련 실험 결과를 확인해보자

클론받은 코드를 보면 간단한 머신러닝과 딥러닝 모델을 훈련시킬 수 있는 샘플 코드들이 있어요. 
ML 폴더의 `mlflow_tracking.py` 파일은  **titanic** 테스크 해결을 위해 `sklearn` 라이브러리 모델을 사용해요.
일단, 간단한 실험을 먼저 해보고 그 결과를 보도록 해보죠 :) 물론 그전에 간단히 코드가 어떻게 구성되어있는지 확인해보면 좋겠죠~?

```
cd ML; python mlflow_tracking.py
```

훈련이 끝나면 `mlruns` 폴더가 생기고 `0` 폴더가 또 생깁니다. 더 들어가보면 알파벳 숫자로 얽힌 폴더 아래에 또 뭔가가 많이 생겨요.
각 폴더들이 샘플 코드와 어떻게 대응될까요? 우선 모델과 데이터를 저장한 것들은 `artifacts`에, 
실험 결과를 측정하는 값은 `metrics`에, 그리고 로깅하고 싶은 파라미터 혹은 실험 값들은 `params` 폴더와 대응돼요.

![folder_structure1](https://user-images.githubusercontent.com/40655873/159262751-03fcc9cf-5105-413e-99b9-665d5c33be53.png)

mlflow의 각 폴더는 아래 그림과 같이 구성돼요. 실험이라는 개념이 있고, 각 실험은 여러번의 실행을 가질 수 있어요.
하나의 유의미한 실험 결과를 얻기 위해 하나의 실험 목표로 여러번 실험 수행을 하게되는 구조를 떠올리면 편할거에요.
이렇게 저장된 결과를 웹을 통해서 확인하기 위해서 아래 명령어를 치고 `https://{ip}:{port}` 로 들어가볼게요.

```mlflow ui -h {ip} -p {port}```
> 예) `mlflow ui -h {127.0.0.0} -p {5000}`, ip는 local host, 기본 포트 5000 사용 시 `mlflow ui` 만 사용 가능


![folder_structure2](https://user-images.githubusercontent.com/40655873/159262759-d9e7b76f-85a8-4926-a602-ec0f0598e284.png)

웹사이트가 뜨면 아래와 같을거에요. 수행된 실험을 누르면 앞서 본 구조에서 **run_id** 값이 일치한 걸 확인할 수 있고, 
코드에 저장한 4종류의 파라미터와 1개의 메트릭이 보이네요! 
artifacts 는 여러가지 파일들이 있는데요. 내 컴퓨터에 저장되어 있는 MLmodel 내용과 동일함을 볼 수 있어요. 

![web1](https://user-images.githubusercontent.com/40655873/159262780-9daca24a-e46d-46af-8831-9c7f602c8e1c.png)

![web2](https://user-images.githubusercontent.com/40655873/159262781-ffe88634-1fd9-4642-ad8c-0959b72cfc3d.png)

한번더 실험을 돌려볼까요? 그러면 **0** 실험에 두번째 실행에 대한 폴더가 생겨요!

![multiruns](https://user-images.githubusercontent.com/40655873/159262762-c60b76da-77f5-4c3d-ac26-441d49cdae67.png)

### 훈련된 모델로 추론 및 서빙을 해보자

`mlflow_inference.py` 파일은 저장되어 있는 모델을 불러와 추론을 하는 구조로 구성돼있어요.
한번 돌려보고 다시 분석해보겠습니다.

```
python mlflow_inference.py
```

위 코드를 수행하면 추론 값이 터미널창에 뜰텐데요. 아래의 그림을 보면서 설명해볼게요.
첫번째 실행을 통해 얻게된 모델을 해당 폴더에서 가져와 모델을 로드하고 테스트 데이터를 인풋으로 넣어주는 간단한 구조에요!

![serving1](https://user-images.githubusercontent.com/40655873/159262777-bbc555ba-a7e9-4539-be8b-eb037b311cd2.png)

이렇게 추론하는 방법 말고도 간단한 서빙도 가능한데요. 2개의 터미널을 키고 실험해볼게요.
아래처럼 첫번째 터미널은 사용할 모델 정보를 입력해서 띄우면 요청이 올 때까지 기다리는 서버 역할을 하게 돼요.
두번째 터미널은 원하는 데이터를 보내고 그 결과값을 얻는 클라이언트 역할이에요.
먼저 서버 역할하는 첫번째 터미널에 명령어를 치고, 두번째 터미널로 요청을 보내면 결과값을 얻게돼요.

```python
# 첫번째 터미널
mlflow models serve -m runs:/{run_id}/ {folder_name} --no-conda
# 두번째 터미널
curl http://{ip_address}:{port}/invocations -H 'Content-Type: application/json' -d '{"columns": ["Pclass", "Sex", "Fare", "SibSp", "Parch"], "data": [[1, 2, 3, 2 ,2], [1, 2, 4, 5, 6]]}'
```
![serving2](https://user-images.githubusercontent.com/40655873/159262778-db950c30-835c-438c-b609-1f1f4405c059.png)

### MLProject를 활용해서 실험을 관리해보자

이번에는 ML 폴더에 `MLProject` 를 만들어서 실험과 실행에 필요한 정보들을 입력해줄건데요.
더 구체적으로 어떤 값들을 넣을 수 있는지는 [mlflow](https://www.mlflow.org/docs/latest/projects.html) 페이지를 참고해주세요.
저는 간단한 이름과 해당 실험을 수행할 때 사용할 명령어를 입력하는 것만 넣어줄거에요!
그리고 다시 mlflow_tutorial 폴더로 돌아와서 새로운 실험을 만들고, 해당 위치에서 mlflow 명령어로 ML 폴더에 있는 실험을 돌려볼겁니다!!

![project1](https://user-images.githubusercontent.com/40655873/159262766-401613ea-c5e7-4ba9-a8df-cc8d70500464.png)

```python
# 실험 생성
mlflow experiments create --experiment-name {실험명}
# 실험 리스트 확인
mlflow experiments list
# 실험 수행
mlflow run ML --experiment-name {실험명}
```


![project2](https://user-images.githubusercontent.com/40655873/159262768-1afdf787-5214-4245-99b5-f3feaaa20d30.png)
결과를 확인해보기 전에 실험을 생성할 수 있는 다른 방법을 알려줄겸 다른 실험을 하나 더 돌려볼건데요.
이번에는 pytorch를 사용한 deep learning 코드를 돌려볼게요! DL 폴더의 `mlflow_tracking.py`에 주석처리되어 있는 부분을 살려주세요.
그리고 실험을 돌려볼게요!! 이 실험은 DL 폴더 안에서 돌려요.

```
python mlflow_tracking.py
```

그리고 다시 `mlflow_tutorial/mlruns` 에서 폴더를 확인해보니 0,1,2 실험이 생성되고 각각의 실행이 기록돼있죠?

![project3](https://user-images.githubusercontent.com/40655873/159262772-e3e7f7e2-2b13-49c3-9b17-e2cb73a71a03.png)

이렇게 만들어진 실험들을 웹에서 다시한번 확인해보면 아래처럼 대응돼요. 
아, 아까 띄워둔 `mlflow ui` 를 껐다면 다시 실행시켜줘야하는 것 잊지마세요!

![project4](https://user-images.githubusercontent.com/40655873/159262774-86b854ff-9be7-4189-bb47-1700ef7e2ccf.png)

아까 parameter, metric, artifacts는 봤는데.. 보통 텐서보드나 wandb에서 보는 UI는 한번도 못보여드린 것 같아요.
마지막 nlp 실험을 들어가서 metric을 누르면 시각화된 결과값들을 볼 수 있어요!

![project5](https://user-images.githubusercontent.com/40655873/159262775-6aaca628-712a-4b64-a3b8-244fbe382341.png)

<br/>

---

 <br/>

# MLflow Tutorial 배경과 후기 with 이정훈 빌더

아마 이쯤되면 튜토리얼을 진행하신 정훈님에 대한 생각도 조금 궁금해지셨을 것 같은데요!
본격적인 인터뷰에 앞서 튜토리얼에 신청해주신 분들은 왜 MLOps를 배우고자 하는 니즈가 있을까요?
우선 튜토리얼은 온라인으로 진행, 선착순으로 인원을 받아 총 3회 진행됐고, 참여자는 총 63명이었어요.
소수의 인원을 제외하고는 MLOps 관련 경험이 없는 반면 대부분의 인원이 왜 배우고 싶은가에 대한 분명하고도 다양한 동기가 있었어요.
요약하자면 **효율적인 머신러닝 파이프라인 구축과 자동화** 그리고 **실제 서비스 적용 및 시스템 확장에 필요성**이 가장 큰 부분이었어요.
그런만큼 본 튜토리얼에서 MLOps의 기본적 개념, 전체적인 생태계와 흐름과 현업 실제 활용 사례에 대해 듣고 싶은 기대가 있었던걸로 응답해주셨어요.
온라인으로 실습을 진행한만큼 불편한 점도 있었겠지만 제가 신청한 마지막 튜토리얼에서 여러 질문들이 오가는 것을 보니 
MLOps에 대한 관심도가 굉장히 높다는 것을 직접 느낄 수 있었어요. 
그리고 왜 *이 분은 MLOps에 관심을 갖게 되고 이런 튜토리얼을 열었을까?* 에 대한 궁금증도 자연스럽게 들었고 인터뷰를 해보았습니다 :D!
그럼 이제 정훈님의 MLOps와의 첫만남, 튜토리얼 진행 동기 및 후기와 향후 계획에 대해서 들어보도록 하겠습니다. 


### 정훈님은 어떤 분이신가요! 

안녕하세요. 저는 현재 인터파크에서 톡집사라는 챗봇 모델 개발을 담당하고 있는 [이정훈](https://www.linkedin.com/in/%EC%A0%95%ED%9B%88-%EC%9D%B4-00b282129/) 입니다.
아마 톡집사라는 챗봇을 처음 들어보셨을 수도 있는데, 톡집사는 CS 전용 챗봇이며 배송 조회, 환불 문의, 교환 요청, 쿠폰 발급과 같은 고객의 다양한 질문에 대해 답변하는 챗봇입니다. 
저는 모델러로서 intent classification 모델과 chatbot open builder 모델을 담당하고 있습니다.
대학원을 졸업하고 여러 기업 중 톡집사 팀을 선택한 이유는 자연어 모델을 실서비스에 적용하고 있었기 때문인데요. 
대학원 재학중에도 많은 논문을 작성하고 다양한 연구를 했지만, 제가 만든 모델이 실제 활용되지 못하는 것이 늘 아쉬웠더만큼 
지금은 사내에서 제가 만든 모델이 서비스에 적용되는 것을 보며 재미있게 개발하고 있습니다.


### 오호.. 모델러로서 어떻게 그리고 왜 MLOps, mlflow의 필요성을 느끼게 됐죠?

MLOps를 처음 접하게 된 것은 호기심과 함께 그 당시 MLOps가 **힙** 해보여 공부를 시작하게 되었습니다.*(웃음)*
20년도쯤에 처음 용어를 듣고 관련자료를 찾아보기 시작한 것 같네요. 그 때는, 이걸 어느곳에 적용되는지 왜 적용해야하는지 감이 오지 않았습니다.
오히려, 작년부터 사내에서 MLOps를 도입하고 있는데 적용하면서 필요성과 효과를 더 잘 느낀 것 같아요.

MLOps 도입을 사내에서 적극적으로 하게 된 이유는 팀 상황 때문이였습니다.
21년에 회사 입사했을 때, 사내에서 모델을 직접적으로 다루는 사람이 저밖에 없었어요.
그래서 MLOps 도구를 활용해 짧은 기간동안 Tracking과 Deployment를 처리하기 위해 사용했습니다.
물론, 웹페이지를 만들어 tracking tool을 만들 수 있고, 실제로 회사에서는 자체적으로 실험 정보와 결과를 관리하는 페이지를 가지고 있었습니다.
배포(Deployment) 또한 마찬가지구요. 
다만 프로젝트의 주제가 바뀔 때마다 이러한 도구들을 커스텀 해주어야 하는 문제가 있었고 다른 서비스 개발자와 협업도 필요했습니다.
**저는 모델러가 직접 이러한 부분까지 자체적으로 커버하기를 원했습니다.**
그래서 MLOps를 도입해 제한적인 인원만 가용할 수 있는 상황에서 제가 원하는 결과를 얻고자 했습니다.

처음에는 다양한 Tracking 도구들 중 Weight&Bias(이하 wandb) 를 사용했었는데, wandb 라이센스 정책이 바뀌면서 유료화가 되었어요.
그래서 오픈 소스이며 tracking 서버를 제가 운영할 수 있는 mlflow를 선택하게 되었습니다.이름도 좀 멋있다고 생각했어요.*(웃음2)*
저희는 사내망이 분리되어 있기 때문에 외부 서비스에 접속하는데 까다로운 보안 절차가 필요한데요.
현재는 mlflow의 트랙킹 서버를 사내망에서 작동중이고 해당 서버에서 모든 프로젝트의 실험 기록들을 저장하고 있습니다.  

  
### 오 흥미로워요! 듣고 있으면 되게 바쁘실 것 같은데.. 이러한 튜토리얼을 진행하게 된 배경은 무엇인가요? 
사실 처음에는 가짜연구소 내에서 MLOps를 사용하시는 분들과 Meet up 행사를 주최하려고 했습니다.
MLOps를 공부하면 공부할수록 어떤 툴을 사용해야하는지, 어떻게 파이프라인을 구성하는지에 대한 컨벤션이 정해져 있지 않다고 느껴졌거든요.
각자 사용하는 방법이 다르기 때문에 서로 의견을 나누고 왜 그렇게 구성했는지 의견을 나누고 싶었습니다.
그런데 막상 MLOps를 사용하는 분들이 많지 않은 것 같더라구요. 
그래서 그 대신 튜토리얼을 운영하며 사람들이 MLOps를 왜 필요로 하는지 알아보자란 생각으로 이어진 것 같아요.
또 평소부터 교육이나 경험을 공유하는 것에 관심이 많아서 간단한 튜토리얼을 진행하게 되었습니다.

### 튜토리얼을 진행하시면서 그럼 어떤점을 느끼셨어요?
생각보다 많은 분들이 MLOps에 관심을 가지고 있으며 필요로한다는 것을 알게되었습니다.
인상적이었던 것은 튜토리얼에 참여하신 분들 중 몇몇 분이 사내 Tracking을 mlflow로 하게되었다고 말씀해주셔서 뿌듯했던 기억이 있습니다.
아쉬웠던점은 원래 제 개인 서버에서 모두 동일한 환경으로 실습을 진행하려 했는데 그 부분이 잘 안된어 아쉬운 것 같아요.
어떤분은 윈도우에서, 어떤 분은 리눅스에서 서로 환경이 다르다보니 실습에 많은 어려움을 겪었던 기억이 있네요. 온라인 상황이어서 더 그랬던 것 같기도 하고요.
아마 다음 튜토리얼 부터는 제 서버에 접속해 모두 같이 실습을 진행할 예정입니다.

### 오, 다음에는 어떤 실습을 진행할 예정이신가요? 
추후에는 BentoML과 Docker 튜토리얼을 진행할 예정입니다.
사내에서 mlflow, BentoML, Docker를 함께 사용해 배포 파이프라인을 구성했는데요.
이번에 Tracking을 담당하는 mlflow에 대해 알아보았으니 BentoML을 통해 패키징하고 API 서버를 띄우는 방법을 알아보고 싶네요.

<br/>

---

<br/>

# 글을 마무리하며
이번 글에서는 MLOps와 mlflow에 대한 간단한 설명, 가짜연구소에서 진행한 간단한 mlflow 실습 내용을 바탕으로 기본적인 기능 사용법 그리고
튜토리얼을 진행한 이정훈 빌더님의 인터뷰 내용을 다루었는데요.
분명 mlflow의 간단한 기능을 알아보았지만, 중간중간 궁금한 것들이 많을 것이라 생각해요.
아마 여러분들이 필요로 하는 많은 기능들이 이미 제공되어 있을테니 [공식 홈페이지](https://www.mlflow.org/docs/latest/concepts.html) 를
참고하셔서 활용해보시길 추천드립니다. 아, 물론 유용한 기능을 가짜연구소에 들어오셔서 공유해주시면 더더욱 좋구요 ^~^!
또한 MLOps에 대해 관심있으신 분들은 정훈님이 다음에 진행할 튜토리얼도 눈여겨봐주세요!

끝으로 저도 직접 찾아보고,따라가며 작성한 글인만큼 수정이 필요한 부분에 대해 연락주시면 감사하겠습니다 :)
그럼 이번 컨텐츠는 이렇게 마무리하고 다음 컨텐츠로 돌아오도록 할게요!

---
가짜연구소 페이지 : https://pseudo-lab.com/  
가짜연구소 slack: https://lnkd.in/er5-5cGy  
문의 : pseudolab.operator@gmail.com

